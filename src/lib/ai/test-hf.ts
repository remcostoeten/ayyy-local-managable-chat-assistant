import { HfInference } from '@huggingface/inference'

async function testHuggingFace() {
  try {
    console.log('üîç Testing Hugging Face connection...\n');

    const hf = new HfInference('REMOVED_TOKEN')

    // Test 1: Basic embedding generation
    console.log('Test 1: Generating embedding for a simple sentence');
    const text = 'This is a test sentence.';
    
    const response = await hf.featureExtraction({
      model: 'sentence-transformers/all-MiniLM-L6-v2',
      inputs: text,
    })

    if (!response) {
      throw new Error('No response from Hugging Face API');
    }

    console.log('‚úì Successfully generated embedding');
    console.log(`‚Ä¢ Response type: ${typeof response}`);
    if (Array.isArray(response)) {
      console.log(`‚Ä¢ Vector length: ${response.length}`);
      console.log(`‚Ä¢ First few dimensions: ${response.slice(0, 3).map(n => typeof n === 'number' ? n.toFixed(4) : n)}\n`);
    }

    console.log('‚ú® Test completed successfully!\n');
  } catch (error) {
    console.error('‚ùå Test failed:', error);
    if (error instanceof Error && error.message.includes('401')) {
      console.error('\n‚ö†Ô∏è Authentication failed. Make sure your HF_ACCESS_TOKEN is set correctly.');
    }
  }
}

// Run the test
testHuggingFace(); 